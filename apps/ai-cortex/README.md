# AI Cortex - Universal Worker

**Version :** 2.0.0  
**Phase :** C - Activation du Sidecar IA  
**Architecture :** Law III - Universal Worker

---

## üéØ Objectif

Service FastAPI g√©n√©rique pour structurer les r√©ponses LLM via `instructor`.  
**AUCUNE logique m√©tier** - Pur proxy de structuration.

---

## üìã Endpoints

### `POST /process-generic` ‚≠ê **PRINCIPAL**

Endpoint universel pour structurer du texte selon un sch√©ma JSON.

**Request:**
```json
{
  "text": "Patient tousse, fi√®vre 39, douleur gorge",
  "schema": {
    "type": "object",
    "properties": {
      "patientId": {"type": "string"},
      "transcript": {"type": "string"},
      "symptoms": {
        "type": "array",
        "items": {"type": "string"}
      },
      "diagnosis": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "code": {"type": "string"},
            "label": {"type": "string"},
            "confidence": {"type": "number"}
          },
          "required": ["code", "label", "confidence"]
        }
      }
    },
    "required": ["patientId", "transcript", "symptoms", "diagnosis"]
  },
  "system_prompt": "Tu es un assistant m√©dical...",  // Optionnel
  "llm_provider": "openai",  // Optionnel: "openai" ou "ollama"
  "llm_model": "gpt-4o-mini",  // Optionnel
  "base_url": "https://api.openai.com/v1"  // Optionnel
}
```

**Response:**
```json
{
  "data": {
    "patientId": "patient_123",
    "transcript": "Patient tousse, fi√®vre 39, douleur gorge",
    "symptoms": ["Toux", "Fi√®vre", "Douleur gorge"],
    "diagnosis": [
      {
        "code": "J11.1",
        "label": "Grippe saisonni√®re",
        "confidence": 0.85
      }
    ]
  }
}
```

---

### `POST /structure` (Alias)

Alias pour compatibilit√© avec le backend existant.

**Request:**
```json
{
  "text": "Patient tousse...",
  "json_schema": { ... }
}
```

---

### `GET /health`

Health check du service.

---

## üîß Configuration

### Variables d'environnement

```bash
# Provider LLM (d√©faut: ollama pour Universal Worker local)
LLM_PROVIDER=ollama   # ou "openai"
LLM_MODEL=gpt-4o-mini # ou "llama3.2" pour Ollama

# Ollama (LLM local) ‚Äî utilis√© quand LLM_PROVIDER=ollama
# Mac + Docker : host.docker.internal pour acc√©der √† Ollama sur la machine h√¥te
# docker-compose avec service ollama : http://ollama:11434/v1
OLLAMA_BASE_URL=http://host.docker.internal:11434/v1
OLLAMA_MODEL=llama3.2

# OpenAI (si provider=openai)
OPENAI_API_KEY=sk-...
LLM_BASE_URL=https://api.openai.com/v1

# Serveur
PORT=8000
HOST=0.0.0.0
```

### D√©marrage

```bash
# Installation des d√©pendances
pip install -r requirements.txt

# D√©marrage
python main.py

# Ou avec uvicorn directement
uvicorn main:app --host 0.0.0.0 --port 8000
```

---

## üèóÔ∏è Architecture

### Law III: Universal Worker

1. **Stateless** : Aucun √©tat interne
2. **G√©n√©rique** : Pas de logique m√©tier hardcod√©e
3. **Construction dynamique** : Mod√®les Pydantic cr√©√©s √† la vol√©e depuis JSON Schema
4. **Provider agnostic** : Support OpenAI et Ollama

### Fonctionnement

```
NestJS (TypeScript)
    ‚Üì
    Convertit Zod Schema ‚Üí JSON Schema (via zodToJsonSchema)
    ‚Üì
    POST /process-generic
    ‚Üì
AI Cortex (Python)
    ‚Üì
    JSON Schema ‚Üí Mod√®le Pydantic dynamique (json_schema_to_pydantic_model)
    ‚Üì
    Instructor + LLM ‚Üí R√©ponse structur√©e
    ‚Üì
    Retour JSON structur√©
    ‚Üì
NestJS
    ‚Üì
    Validation avec Zod Schema
```

---

## üß™ Tests

### Test avec curl

```bash
curl -X POST http://localhost:8000/process-generic \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Patient tousse, fi√®vre 39",
    "schema": {
      "type": "object",
      "properties": {
        "symptoms": {
          "type": "array",
          "items": {"type": "string"}
        }
      },
      "required": ["symptoms"]
    }
  }'
```

### Test avec ConsultationSchema

Le backend NestJS convertit automatiquement le Zod Schema en JSON Schema et appelle cet endpoint.

---

## üì¶ D√©pendances

- `fastapi` : Framework web
- `uvicorn` : Serveur ASGI
- `pydantic` : Validation et mod√®les dynamiques
- `instructor` : Structuration LLM
- `openai` : Client OpenAI compatible (OpenAI + Ollama)

---

## ‚ö†Ô∏è Notes Importantes

1. **Construction dynamique** : Les mod√®les Pydantic sont cr√©√©s √† la vol√©e - **pas de hardcoding**
2. **JSON Schema standard** : Le sch√©ma doit √™tre au format JSON Schema (compatible avec OpenAPI3)
3. **Provider support** : OpenAI et Ollama support√©s
4. **Stateless** : Chaque requ√™te est ind√©pendante

---

*AI Cortex - Universal Worker V2.0.0*
