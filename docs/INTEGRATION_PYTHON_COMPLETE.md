# ‚úÖ Int√©gration Python Sidecar - COMPL√àTE

**Date :** 2026-01-21  
**Version :** BaseVitale V162+  
**Status :** ‚úÖ **OP√âRATIONNEL**

---

## üéØ Objectif Atteint

Le sidecar Python (AI Cortex) est maintenant **connect√©** au backend NestJS via la m√©thode `ScribeService.analyze()`.

---

## ‚úÖ Modifications R√©alis√©es

### **Fichier :** `apps/api/src/scribe/scribe.service.ts`

#### **M√©thode `analyze()` - Gestion Mode LOCAL**

**Avant :**
```typescript
if (aiMode === 'MOCK') {
  // ... logique MOCK
} else {
  // Tous les autres modes ‚Üí analyzeConsultation()
  return this.analyzeConsultation(text);
}
```

**Apr√®s :**
```typescript
if (aiMode === 'MOCK') {
  // ... logique MOCK
} else if (aiMode === 'LOCAL') {
  // NOUVEAU : Appel direct du sidecar Python
  // 1. Conversion Zod ‚Üí JSON Schema
  // 2. POST /process-generic
  // 3. Validation Zod
  // 4. Sauvegarde Postgres
  // 5. Fallback MOCK si erreur
} else {
  // Mode CLOUD ‚Üí analyzeConsultation()
  return this.analyzeConsultation(text);
}
```

---

## üîÑ Flux D√©taill√© Mode LOCAL

### **√âtape 1 : Conversion Zod ‚Üí JSON Schema**
```typescript
const jsonSchema = zodToJsonSchema(ConsultationSchema);
```
- Utilise `zodToJsonSchema` depuis `@basevitale/shared`
- Convertit le sch√©ma Zod en JSON Schema standard

### **√âtape 2 : D√©termination URL Sidecar**
```typescript
const sidecarUrl = process.env.NODE_ENV === 'production' 
  ? `http://ai-cortex:8000`  // Nom du service Docker
  : this.pythonSidecarUrl;    // localhost:8000
```
- D√©tection automatique de l'environnement
- Support Docker et d√©veloppement local

### **√âtape 3 : Appel HTTP POST**
```typescript
POST http://localhost:8000/process-generic
{
  "text": "Patient tousse, fi√®vre 39",
  "schema": { ... } // JSON Schema
}
```
- Timeout : 60 secondes
- Headers : `Content-Type: application/json`

### **√âtape 4 : Validation Zod**
```typescript
const validatedConsultation = ConsultationSchema.parse(structuredData);
```
- Garantit la structure des donn√©es
- Law I: Contract-First Intelligence

### **√âtape 5 : Sauvegarde Postgres**
```typescript
await this.prisma.consultationDraft.create({
  data: {
    patientId: validatedConsultation.patientId,
    status: 'DRAFT',
    structuredData: validatedConsultation
  }
});
```
- M√™me logique que mode MOCK
- Statut : `DRAFT`

### **√âtape 6 : Fallback MOCK**
```typescript
catch (error) {
  // Log erreur
  // G√©n√©ration MOCK
  // Sauvegarde
  // Retour MOCK
}
```
- Mode d√©grad√© si Python indisponible
- Le front continue de fonctionner

---

## üìä M√©triques Disponibles

### Succ√®s
- ‚úÖ `scribe.analyze.local.success` - Appels r√©ussis
- ‚úÖ `scribe.analyze.local.saved` - Sauvegardes r√©ussies
- ‚úÖ `scribe.analyze.local.duration` - Temps de traitement

### Erreurs & Fallback
- ‚úÖ `scribe.analyze.local.error` - Erreurs sidecar
- ‚úÖ `scribe.analyze.local.validation_error` - Erreurs validation
- ‚úÖ `scribe.analyze.local.save_error` - Erreurs sauvegarde
- ‚úÖ `scribe.analyze.local.fallback_to_mock` - Fallbacks activ√©s

---

## üß™ Test de l'Int√©gration

### Pr√©requis

1. **D√©marrer le sidecar Python :**
```bash
# Option 1 : Docker
docker-compose up -d ai-cortex

# Option 2 : Manuel
cd apps/ai-cortex
python main.py
```

2. **Configurer le backend :**
```env
AI_MODE=LOCAL
AI_CORTEX_URL=http://localhost:8000
```

### Test Manuel

```bash
# Test l'endpoint /scribe/analyze
curl -X POST http://localhost:3000/api/scribe/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Patient tousse depuis 3 jours, fi√®vre √† 39¬∞C, douleur √† la gorge"
  }'
```

### V√©rifier les Logs

**Backend (succ√®s) :**
```
[LOCAL] Appel du sidecar Python via /process-generic
[LOCAL] ConsultationSchema converti en JSON Schema
[LOCAL] Appel vers: http://localhost:8000/process-generic
[LOCAL] Donn√©es structur√©es re√ßues du sidecar Python
[LOCAL] Consultation valid√©e avec succ√®s par ConsultationSchema
[LOCAL] ConsultationDraft sauvegard√© avec ID: ...
```

**Backend (fallback) :**
```
[LOCAL] Erreur lors de l'appel au sidecar Python
[LOCAL] Fallback vers MOCK en mode d√©grad√©
[LOCAL] ConsultationDraft fallback sauvegard√©
```

---

## üîß Configuration

### Variables d'Environnement Requises

```env
# Mode IA
AI_MODE=LOCAL

# URL Sidecar (optionnel)
AI_CORTEX_URL=http://localhost:8000  # Development
# AI_CORTEX_URL=http://ai-cortex:8000  # Docker
```

### Configuration Python Sidecar

```env
# Dans docker-compose.yml ou .env
LLM_PROVIDER=openai  # ou "ollama"
OPENAI_API_KEY=sk-...  # Si provider=openai
```

---

## ‚úÖ Garanties

### R√©silience
- ‚úÖ **Fallback automatique** : MOCK si Python indisponible
- ‚úÖ **Mode d√©grad√©** : Front continue de fonctionner
- ‚úÖ **Timeout 60s** : √âvite les blocages
- ‚úÖ **Logging d√©taill√©** : Toutes les erreurs logg√©es

### Validation
- ‚úÖ **Validation Zod stricte** : Garantit la structure
- ‚úÖ **Contract-First** : Zod ‚Üí JSON Schema ‚Üí Pydantic ‚Üí Zod

### Architecture
- ‚úÖ **Law I respect√©e** : Contract-First Intelligence
- ‚úÖ **Law III respect√©e** : Universal Worker g√©n√©rique
- ‚úÖ **Stateless** : Aucun √©tat partag√©

---

## üéØ R√©sultat Final

### Modes Disponibles

| Mode | Fonctionnement | Status |
|------|---------------|--------|
| **MOCK** | Faker (donn√©es factices) | ‚úÖ Op√©rationnel |
| **LOCAL** | Python Sidecar + LLM | ‚úÖ **CONNECT√â** |
| **CLOUD** | OpenAI direct (NestJS) | ‚úÖ Op√©rationnel |

### Flux Complet

```
Frontend ‚Üí NestJS ‚Üí Python Sidecar ‚Üí LLM ‚Üí Python ‚Üí NestJS ‚Üí Postgres ‚Üí Frontend
```

**Avec Fallback :**
```
Frontend ‚Üí NestJS ‚Üí Python Sidecar (‚ùå) ‚Üí MOCK ‚Üí NestJS ‚Üí Postgres ‚Üí Frontend
```

---

## üìà Prochaines √âtapes

1. ‚úÖ Connexion compl√©t√©e
2. ‚è≠Ô∏è Tests E2E complets
3. ‚è≠Ô∏è Optimisation performance
4. ‚è≠Ô∏è Monitoring avanc√©

---

**Int√©gration Python Sidecar - ‚úÖ COMPL√àTE ET OP√âRATIONNELLE**

*BaseVitale V162+ - Architecture Neuro-Symbiotique*
